{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import copy\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from Common import NeuralNet, EarlyStopping, TrainingConfig"
   ],
   "id": "d05e7c470be7b44e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "class FirnIPINN:\n",
    "    def __init__(self, n_int, n_sb, n_tb, n_meas, lambda_u=10, n_hidden_layers=4, neurons=20, lambda_m=10, n_hidden_layers_cf=4, neurons_cf=20, retrain_seed=42, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "\n",
    "        self.device = device\n",
    "        self.dtype = torch.float32\n",
    "\n",
    "\n",
    "        self.n_int = n_int\n",
    "        self.n_sb = n_sb\n",
    "        self.n_tb = n_tb\n",
    "        self.n_meas = n_meas\n",
    "\n",
    "\n",
    "        self.f = 0.2\n",
    "        M_alpha, g = 0.04, 9.8\n",
    "        R, T = 8.314, 260\n",
    "        self.M = (M_alpha * g) / (R * T)\n",
    "        self.G = 10+0.03\n",
    "        self.F = 200+485\n",
    "        # Extrema of the solution domain (t,x)\n",
    "        time_domain = [0, 1]\n",
    "        space_domain = [0, 1]\n",
    "        self.Te = time_domain[1]\n",
    "        self.zf = space_domain[1]\n",
    "        self.domain = torch.tensor([time_domain, space_domain])\n",
    "\n",
    "        # Parameter to balance the role of data and PDE\n",
    "        self.lambda_u = lambda_u\n",
    "\n",
    "        # Parameter to balance the role of measurement data and PDE\n",
    "        self.lambda_m = lambda_m\n",
    "\n",
    "        # Generator of Sobol sequences\n",
    "        self.soboleng = torch.quasirandom.SobolEngine(dimension=self.domain.shape[0])\n",
    "        # F Dense NN to approximate the solution of the underlying heat equation\n",
    "        self.approximate_solution = NeuralNet(input_dimension=self.domain.shape[0], output_dimension=1, n_hidden_layers=n_hidden_layers, neurons=neurons, retrain_seed=retrain_seed, device=device).to(device)\n",
    "\n",
    "        self.approximate_coefficient = NeuralNet(input_dimension=self.domain.shape[0], output_dimension=1, n_hidden_layers=n_hidden_layers_cf, neurons=neurons_cf, retrain_seed=retrain_seed, device=device).to(device)\n",
    "\n",
    "        self.ms = lambda x: torch.mean(torch.square(x))\n",
    "        # Create directory to save plots\n",
    "        path = os.path.join('/Users/omar/Desktop/Thesis/plots', self.__class__.__name__, datetime.now().strftime('%Y-%m-%d %H-%M-%S'))\n",
    "        os.makedirs(path)\n",
    "        self.path = path\n",
    "\n",
    "    # Function to linearly transform a tensor whose value is between 0 and 1\n",
    "    # to a tensor whose values are between the domain extrema\n",
    "    def convert(self, tens):\n",
    "        assert (tens.shape[1] == self.domain.shape[0])\n",
    "        return tens * (self.domain[:, 1] - self.domain[:, 0]) + self.domain[:, 0]\n",
    "\n",
    "    def save_config(self, optimizer):\n",
    "        class_config = {\n",
    "            'n_int': self.n_int,\n",
    "            'n_sb': self.n_sb,\n",
    "            'n_tb': self.n_tb,\n",
    "            'n_meas': self.n_meas,\n",
    "            'lambda_u': self.lambda_u,\n",
    "            'lambda_m': self.lambda_m,\n",
    "            'n_hidden_layers': self.approximate_solution.n_hidden_layers,\n",
    "            'neurons': self.approximate_solution.neurons,\n",
    "            'n_hidden_layers_cf': self.approximate_coefficient.n_hidden_layers,\n",
    "            'neurons_cf': self.approximate_coefficient.neurons,\n",
    "            'retrain_seed': self.approximate_solution.retrain_seed,\n",
    "            'device': self.device,\n",
    "            'optimizer_config': optimizer.defaults\n",
    "        }\n",
    "        # Save configuration in json file\n",
    "        with open(f'{self.path}/config.json', 'w') as f:\n",
    "            json.dump(class_config, f)\n",
    "\n",
    "\n",
    "    def initial_condition(self, x):\n",
    "        return torch.zeros(x.shape[0], 1)\n",
    "\n",
    "    def left_boundary_condition(self, t):\n",
    "        return 2* ((self.Te*t) **0.25)\n",
    "\n",
    "    def right_boundary_condition(self, t):\n",
    "        return torch.zeros(t.shape[0], 1)\n",
    "\n",
    "    def exact_coefficient(self, inputs):\n",
    "        x = inputs[:, 1]\n",
    "        D = 200 - 199.98*x\n",
    "        return D\n",
    "\n",
    "    def compute_pde_residual(self, input_int):\n",
    "        input_int.requires_grad = True\n",
    "        u = self.approximate_solution(input_int).reshape(-1,)\n",
    "        D_alpha = self.approximate_coefficient(input_int).reshape(-1,)\n",
    "        grad_u = torch.autograd.grad(u.sum(), input_int, create_graph=True)[0]\n",
    "        grad_u_t = grad_u[:, 0]\n",
    "        grad_u_x = grad_u[:, 1]\n",
    "        grad_u_xx = torch.autograd.grad(grad_u_x.sum(), input_int, create_graph=True)[0][:, 1]\n",
    "\n",
    "        # get the derivative of D_alpha\n",
    "        D_alpha_x = torch.autograd.grad(D_alpha.sum(), input_int, create_graph=True)[0][:, 1]\n",
    "\n",
    "        left_side = (grad_u_t * self.f)/self.Te + (grad_u_x*self.f*self.F)/self.zf + u*self.G\n",
    "\n",
    "        # get the ride side of the equation\n",
    "        right_side_1 = D_alpha_x*grad_u_x/self.zf**2 - D_alpha_x*u*self.M/self.zf\n",
    "        right_side_2 = D_alpha*grad_u_xx/self.zf**2 - D_alpha*grad_u_x*self.M/self.zf\n",
    "        right_side = right_side_1 + right_side_2\n",
    "\n",
    "        residual = (left_side - right_side)\n",
    "        return residual.reshape(-1, )\n",
    "\n",
    "    def apply_right_boundary_derivative(self, inp_train_sb_right):\n",
    "        inp_train_sb_right.requires_grad = True\n",
    "        u = self.approximate_solution(inp_train_sb_right)\n",
    "        grad_u = torch.autograd.grad(u.sum(), inp_train_sb_right, create_graph=True)[0]\n",
    "        grad_u_x = grad_u[:, 1]\n",
    "        D_alpha = self.approximate_coefficient(inp_train_sb_right)\n",
    "        return self.ms(D_alpha*(grad_u_x/self.zf - self.M*u) - self.right_boundary_condition(inp_train_sb_right[:, 0]))\n",
    "\n",
    "    def get_exact_solution(self, compare=False):\n",
    "        path = r'/Users/omar/Desktop/Thesis/thesis_code/PINN/firn_exact_data.xlsx'\n",
    "        data = pd.read_excel(path, header=None)\n",
    "        x = data[0].values\n",
    "        t = data[1].values\n",
    "        inputs = torch.tensor(np.stack((t, x), axis=1), dtype=self.dtype, device=self.device)\n",
    "\n",
    "        exact_output = data[2].values.reshape(-1, )\n",
    "        exact_output = torch.tensor(exact_output, dtype=self.dtype, device=self.device)\n",
    "        if compare:\n",
    "            return inputs, exact_output\n",
    "        # self.n_meas is the % of how much data we want to use\n",
    "        n_points = int(self.n_meas * len(exact_output))\n",
    "        idx = np.random.choice(len(exact_output), n_points, replace=False)\n",
    "        inputs = inputs[idx]\n",
    "        exact_output = exact_output[idx]\n",
    "        return inputs, exact_output\n",
    "    ###############################################################################################\n",
    "    # add points\n",
    "    def add_temporal_boundary_points(self):\n",
    "        t0 = self.domain[0, 0]\n",
    "        input_tb = self.convert(self.soboleng.draw(self.n_tb))\n",
    "        input_tb = input_tb.to(self.dtype).to(self.device)\n",
    "        input_tb[:, 0] = torch.full(input_tb[:, 0].shape, t0)\n",
    "        output_tb = self.initial_condition(input_tb[:, 1]).reshape(-1, 1)\n",
    "        output_tb = output_tb.to(self.dtype).to(self.device)\n",
    "        return input_tb, output_tb\n",
    "\n",
    "    def add_spatial_boundary_points_left(self):\n",
    "        x_left = self.domain[1, 0]\n",
    "        input_sb = self.convert(self.soboleng.draw(self.n_sb))\n",
    "        input_sb = input_sb.to(self.dtype).to(self.device)\n",
    "        input_sb_left = torch.clone(input_sb)\n",
    "        input_sb_left[:, 1] = torch.full(input_sb_left[:, 1].shape, x_left)\n",
    "\n",
    "        output_sb_left = self.left_boundary_condition(input_sb_left[:, 0]).reshape(-1, 1)\n",
    "        output_sb_left = output_sb_left.to(self.dtype).to(self.device)\n",
    "        return input_sb_left, output_sb_left\n",
    "\n",
    "    def add_spatial_boundary_points_right(self):\n",
    "        x_right = self.domain[1, 1]\n",
    "        input_sb = self.convert(self.soboleng.draw(self.n_sb))\n",
    "        input_sb = input_sb.to(self.dtype).to(self.device)\n",
    "        input_sb_right = torch.clone(input_sb)\n",
    "\n",
    "        input_sb_right[:, 1] = torch.full(input_sb_right[:, 1].shape, x_right)\n",
    "\n",
    "        output_sb_right = self.right_boundary_condition(input_sb_right[:, 0]).reshape(-1, 1)\n",
    "        output_sb_right = output_sb_right.to(self.dtype).to(self.device)\n",
    "        return input_sb_right, output_sb_right\n",
    "\n",
    "\n",
    "    #  Function returning the input-output tensor required to assemble the training set S_int corresponding to the interior domain where the PDE is enforced\n",
    "    def add_interior_points(self):\n",
    "        input_int = self.convert(self.soboleng.draw(self.n_int))\n",
    "        input_int = input_int.to(self.dtype).to(self.device)\n",
    "        output_int = torch.zeros((input_int.shape[0], 1))\n",
    "        output_int = output_int.to(self.dtype).to(self.device)\n",
    "        return input_int, output_int\n",
    "\n",
    "\n",
    "    def get_measurement_data(self):\n",
    "        torch.random.manual_seed(42)\n",
    "        input_meas, output_meas = self.get_exact_solution()\n",
    "        return input_meas, output_meas\n",
    "\n",
    "    # Function returning the training sets S_sb, S_tb, S_int as dataloader\n",
    "    def assemble_datasets(self):\n",
    "        input_sb_left, output_sb_left = self.add_spatial_boundary_points_left()\n",
    "        input_sb_right, output_sb_right = self.add_spatial_boundary_points_right()\n",
    "        input_tb, output_tb = self.add_temporal_boundary_points()  # S_tb\n",
    "        input_int, output_int = self.add_interior_points()         # S_int\n",
    "        training_set_sb_left = DataLoader(torch.utils.data.TensorDataset(input_sb_left, output_sb_left), batch_size=self.n_sb, shuffle=False)\n",
    "        training_set_sb_right = DataLoader(torch.utils.data.TensorDataset(input_sb_right, output_sb_right), batch_size=self.n_sb, shuffle=False)\n",
    "        training_set_tb = DataLoader(torch.utils.data.TensorDataset(input_tb, output_tb), batch_size=self.n_tb, shuffle=False)\n",
    "        training_set_int = DataLoader(torch.utils.data.TensorDataset(input_int, output_int), batch_size=self.n_int, shuffle=False)\n",
    "        return training_set_sb_left, training_set_sb_right, training_set_tb, training_set_int\n",
    "\n",
    "    # Function to compute the terms required in the definition of the TEMPORAL boundary residual\n",
    "    def apply_initial_condition(self, input_tb):\n",
    "        u_pred_tb = self.approximate_solution(input_tb)\n",
    "        u_pred_tb = u_pred_tb.to(self.dtype).to(self.device)\n",
    "        return u_pred_tb\n",
    "\n",
    "    # Function to compute the terms required in the definition of the SPATIAL boundary residual\n",
    "    def apply_boundary_conditions_left(self, input_sb):\n",
    "        u_pred_sb = self.approximate_solution(input_sb)\n",
    "        u_pred_sb = u_pred_sb.to(self.dtype).to(self.device)\n",
    "        return u_pred_sb\n",
    "\n",
    "    def apply_boundary_conditions_right(self, input_sb):\n",
    "        u_pred_sb = self.approximate_solution(input_sb)\n",
    "        u_pred_sb = u_pred_sb.to(self.dtype).to(self.device)\n",
    "        return u_pred_sb\n",
    "\n",
    "    ################################################################################################\n",
    "    def optimizer_LBFGS(self, config):\n",
    "        \"\"\"Create LBFGS optimizer with specified configuration.\"\"\"\n",
    "        return torch.optim.LBFGS(\n",
    "            list(self.approximate_solution.parameters())+list(self.approximate_coefficient.parameters()),\n",
    "            lr=float(config.lr),\n",
    "            max_iter=config.max_iter,\n",
    "            max_eval=config.max_eval,\n",
    "            history_size=config.history_size,\n",
    "            line_search_fn=config.line_search_fn,\n",
    "            tolerance_change=1.0 * np.finfo(float).eps\n",
    "        )\n",
    "\n",
    "    def optimizer_ADAM(self, lr=1e-5):\n",
    "        return torch.optim.Adam(list(self.approximate_solution.parameters())+list(self.approximate_coefficient.parameters()), lr=float(lr))\n",
    "\n",
    "# Function to compute the total loss (weighted sum of spatial boundary loss, temporal boundary loss and interior loss)\n",
    "    def compute_loss(self, train_points):\n",
    "        (inp_train_sb_left, u_train_sb_left, inp_train_sb_right, u_train_sb_right,\n",
    "         inp_train_tb, u_train_tb, inp_train_int) = train_points\n",
    "        inp_train_meas, u_train_meas = self.get_measurement_data()\n",
    "        u_pred_meas = self.approximate_solution(inp_train_meas)\n",
    "\n",
    "        # Compute boundary predictions\n",
    "        u_pred_sb_left = self.apply_boundary_conditions_left(inp_train_sb_left)\n",
    "        u_pred_sb_right = self.apply_boundary_conditions_right(inp_train_sb_right)\n",
    "        u_pred_tb = self.apply_initial_condition(inp_train_tb)\n",
    "\n",
    "        # Validate shapes\n",
    "        assert (u_pred_sb_left.shape[1] == u_train_sb_left.shape[1])\n",
    "        assert (u_pred_sb_right.shape[1] == u_train_sb_right.shape[1])\n",
    "        assert (u_pred_tb.shape[1] == u_train_tb.shape[1])\n",
    "\n",
    "        # Compute residuals\n",
    "        r_int = self.compute_pde_residual(inp_train_int)\n",
    "        r_sb_left = u_train_sb_left - u_pred_sb_left\n",
    "        r_sb_right = u_train_sb_right - u_pred_sb_right\n",
    "        r_tb = u_train_tb - u_pred_tb\n",
    "        r_meas = u_train_meas - u_pred_meas\n",
    "\n",
    "        # Compute individual losses\n",
    "        loss_sb_left = self.ms(r_sb_left)\n",
    "        loss_sb_right = self.ms(r_sb_right)\n",
    "        loss_tb = self.ms(r_tb)\n",
    "        loss_int = self.ms(r_int)\n",
    "        loss_meas = self.ms(r_meas)\n",
    "\n",
    "        # Compute boundary loss\n",
    "        loss_u = loss_sb_left + loss_tb + loss_sb_right + loss_meas\n",
    "\n",
    "        # Total loss with log scaling\n",
    "        loss = torch.log10(self.lambda_u * loss_u + loss_int)\n",
    "\n",
    "        return loss, loss_u, loss_int, loss_meas\n",
    "\n",
    "    def enhanced_fit(self, num_epochs, optimizer, config=None, verbose=True):\n",
    "        if config is None:\n",
    "            config = TrainingConfig(num_epochs=num_epochs)\n",
    "\n",
    "        self.save_config(optimizer)\n",
    "        history = {\n",
    "            'total_loss': [],\n",
    "            'pde_loss': [],\n",
    "            'boundary_loss': [],\n",
    "            'coefficient_loss': [],\n",
    "            'learning_rate': []\n",
    "        }\n",
    "\n",
    "        # Initialize early stopping\n",
    "        early_stopping = EarlyStopping(\n",
    "            patience=config.early_stopping_patience,\n",
    "            min_delta=config.early_stopping_min_delta\n",
    "        )\n",
    "\n",
    "        # Setup scheduler for ADAM\n",
    "        is_lbfgs = isinstance(optimizer, torch.optim.LBFGS)\n",
    "        scheduler = None\n",
    "        if not is_lbfgs:\n",
    "            scheduler = ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode='min',\n",
    "                factor=config.scheduler_factor,\n",
    "                patience=config.scheduler_patience,\n",
    "                min_lr=config.scheduler_min_lr,\n",
    "                verbose=verbose\n",
    "            )\n",
    "\n",
    "        # Get training datasets\n",
    "        training_sets = self.assemble_datasets()\n",
    "        training_set_sb_left, training_set_sb_right, training_set_tb, training_set_int = training_sets\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_losses = []\n",
    "\n",
    "            if verbose and epoch % max(1, num_epochs // 10) == 0:\n",
    "                print(f\"\\nEpoch [{epoch + 1}/{num_epochs}]\")\n",
    "\n",
    "            for data in zip(training_set_sb_left, training_set_sb_right, training_set_tb, training_set_int):\n",
    "                inp_train_sb_left, u_train_sb_left = data[0]\n",
    "                inp_train_sb_right, u_train_sb_right = data[1]\n",
    "                inp_train_tb, u_train_tb = data[2]\n",
    "                inp_train_int, _ = data[3]\n",
    "\n",
    "                def closure():\n",
    "                    if is_lbfgs:\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                    train_points = (inp_train_sb_left, u_train_sb_left, inp_train_sb_right, u_train_sb_right, inp_train_tb, u_train_tb, inp_train_int)\n",
    "\n",
    "                    loss, loss_u, loss_int, loss_meas = self.compute_loss(train_points)\n",
    "                    loss.backward()\n",
    "\n",
    "                    epoch_losses.append({\n",
    "                        'total': loss.item(),\n",
    "                        'pde': torch.log10(loss_int).item(),\n",
    "                        'boundary': torch.log10(loss_u).item(),\n",
    "                        'coefficient': torch.log10(loss_meas).item()\n",
    "                    })\n",
    "\n",
    "                    return loss\n",
    "\n",
    "                if is_lbfgs:\n",
    "                    optimizer.step(closure)\n",
    "                else:\n",
    "                    optimizer.zero_grad()\n",
    "                    loss = closure()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # Calculate average losses\n",
    "            avg_losses = {\n",
    "                k: np.mean([loss[k] for loss in epoch_losses])\n",
    "                for k in ['total', 'pde', 'boundary', 'coefficient']\n",
    "            }\n",
    "\n",
    "            # Update history\n",
    "            history['total_loss'].append(avg_losses['total'])\n",
    "            history['pde_loss'].append(avg_losses['pde'])\n",
    "            history['boundary_loss'].append(avg_losses['boundary'])\n",
    "            history['coefficient_loss'].append(avg_losses['coefficient'])\n",
    "            history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "            # Update scheduler\n",
    "            if scheduler is not None:\n",
    "                scheduler.step(avg_losses['total'])\n",
    "\n",
    "            # Print progress\n",
    "            if verbose and epoch % max(1, num_epochs // 10) == 0:\n",
    "                print(f\"Total Loss: {avg_losses['total']:.6f} | \"\n",
    "                      f\"Boundary Loss: {avg_losses['boundary']:.6f} | \"\n",
    "                      f\"PDE Loss: {avg_losses['pde']:.6f} | \"\n",
    "                      f\"Coefficient Loss: {avg_losses['coefficient']:.6f} | \"\n",
    "                      f\"LR: {optimizer.param_groups[0]['lr']:.6e}\")\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping(self.approximate_solution, avg_losses['total']):\n",
    "                if verbose:\n",
    "                    print(f\"\\nEarly stopping triggered at epoch {epoch + 1}\")\n",
    "                early_stopping.restore_best_weights(self.approximate_solution)\n",
    "                break\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\nTraining completed. Final loss: {history['total_loss'][-1]:.6f}\")\n",
    "\n",
    "        return history\n",
    "    ################################################################################################\n",
    "    def get_pde_points(self, n_points):\n",
    "        inputs, exact_output = self.get_exact_solution(compare=True)\n",
    "        output = self.approximate_solution(inputs).reshape(-1, )\n",
    "        return inputs, output, exact_output\n",
    "\n",
    "    def get_coefficient_points(self, n_points):\n",
    "        inputs = self.soboleng.draw(n_points)\n",
    "        inputs = self.convert(inputs)\n",
    "        output = self.approximate_coefficient(inputs).reshape(-1, )\n",
    "        exact_output = self.exact_coefficient(inputs).reshape(-1, )\n",
    "        return inputs, output, exact_output\n",
    "\n",
    "    def relative_L2_error(self, n_points=10000, function='pde'):\n",
    "        if function == 'pde':\n",
    "            inputs, output, exact_output = self.get_pde_points(n_points)\n",
    "        else:\n",
    "            inputs, output, exact_output = self.get_coefficient_points(n_points)\n",
    "        err = (torch.mean((output - exact_output) ** 2) / torch.mean(exact_output ** 2)) ** 0.5\n",
    "        print(f'{function} loss:')\n",
    "        print('L2 Relative Error Norm: {:.6e}'.format(err.item()))\n",
    "        with open(f'{self.path}/relative_error.txt', 'a') as f:\n",
    "            f.write(f'{function} loss:\\n')\n",
    "            f.write('L2 Relative Error Norm: {:.6e}\\n'.format(err.item()))\n",
    "        return inputs, output, exact_output\n",
    "\n",
    "    def plotting_solution(self, n_points=50000, function='pde'):\n",
    "        inputs, output, exact_output = self.relative_L2_error(n_points, function)\n",
    "        inputs = inputs.cpu()\n",
    "        output = output.cpu()\n",
    "        exact_output = exact_output.cpu()\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(16, 8), dpi=150)\n",
    "        im1 = axs[0].scatter(inputs[:, 1].detach(), inputs[:, 0].detach(), c=exact_output.detach(), cmap='jet')\n",
    "        axs[0].set_xlabel('x')\n",
    "        axs[0].set_ylabel('t')\n",
    "        plt.colorbar(im1, ax=axs[0])\n",
    "        axs[0].grid(True, which='both', ls=':')\n",
    "        im2 = axs[1].scatter(inputs[:, 1].detach(), inputs[:, 0].detach(), c=output.detach(), cmap='jet')\n",
    "        axs[1].set_xlabel('x')\n",
    "        axs[1].set_ylabel('t')\n",
    "        plt.colorbar(im2, ax=axs[1])\n",
    "        axs[1].grid(True, which='both', ls=':')\n",
    "        title = 'Solution' if function == 'pde' else 'Coefficient'\n",
    "        axs[0].set_title(f'Exact {title}')\n",
    "        axs[1].set_title(f'Approximate {title}')\n",
    "        plt.savefig(f'{self.path}/{title}.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def plot_training_points(self):\n",
    "        # Plot the input training points\n",
    "        input_sb_left, _ = self.add_spatial_boundary_points_left()\n",
    "        input_sb_right_, _= self.add_spatial_boundary_points_right()\n",
    "        input_tb_, _ = self.add_temporal_boundary_points()\n",
    "        input_int_, _ = self.add_interior_points()\n",
    "        input_meas_, output_meas_ = self.get_measurement_data()\n",
    "\n",
    "        input_sb_left_ = copy.deepcopy(input_sb_left).cpu()\n",
    "        input_sb_right_ = copy.deepcopy(input_sb_right_).cpu()\n",
    "        input_tb_ = copy.deepcopy(input_tb_).cpu()\n",
    "        input_int_ = copy.deepcopy(input_int_).cpu()\n",
    "        input_meas_ = copy.deepcopy(input_meas_).cpu()\n",
    "\n",
    "        plt.figure(figsize=(16, 8), dpi=150)\n",
    "        plt.scatter(input_sb_left_[:, 1].detach().numpy(), input_sb_left_[:, 0].detach().numpy(), label='Left Boundary Points')\n",
    "        plt.scatter(input_sb_right_[:, 1].detach().numpy(), input_sb_right_[:, 0].detach().numpy(), label='Right Boundary Points')\n",
    "        plt.scatter(input_int_[:, 1].detach().numpy(), input_int_[:, 0].detach().numpy(), label='Interior Points')\n",
    "        plt.scatter(input_tb_[:, 1].detach().numpy(), input_tb_[:, 0].detach().numpy(), label='Initial Points')\n",
    "        plt.scatter(input_meas_[:, 1].detach().numpy(), input_meas_[:, 0].detach().numpy(), label='Measurement Points')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('t')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'{self.path}/training_points.png')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def plot_train_loss(self, hist):\n",
    "        hist = hist['total_loss']\n",
    "        plt.figure(dpi=150)\n",
    "        plt.grid(True, which=\"both\", ls=\":\")\n",
    "        plt.plot(np.arange(1, len(hist) + 1), hist, label=\"Train Loss\")\n",
    "        plt.xscale(\"log\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel('Log10 Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'{self.path}/train_loss.png')\n",
    "        plt.show()"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testing",
   "id": "c8858329edc828c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Testing\n",
    "config = TrainingConfig(\n",
    "    num_epochs=1,\n",
    "    early_stopping_patience=20,\n",
    "    max_iter=10,\n",
    "    lr=0.8\n",
    ")\n",
    "pde = FirnIPINN(n_int=256, n_sb=64, n_tb=64, n_meas=40)"
   ],
   "id": "44e2d19a72efba0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pde.plot_training_points()",
   "id": "7fe24809b81d7bab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "optimizer = pde.optimizer_LBFGS(config)\n",
    "start = time.time()\n",
    "history = pde.enhanced_fit(\n",
    "    num_epochs=config.num_epochs,\n",
    "    optimizer=optimizer,\n",
    "    config=config,\n",
    "    verbose=True\n",
    ")\n",
    "end = time.time()\n",
    "print('Time taken: ', end - start)\n",
    "with open(f'{pde.path}/time.txt', 'w') as f:\n",
    "    f.write('Time taken: {:.6f}'.format(end - start))"
   ],
   "id": "62e3e1b006749d95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pde.plot_train_loss(history)",
   "id": "d2f1ee02045c5b12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pde.plotting_solution(50000, function='pde')",
   "id": "222134305a98c21d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pde.plotting_solution(50000, function='coefficient')",
   "id": "5f4273bda2dcb115",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
